ğŸ“„ GenAI Multi-Document Q&A System
An advanced Retrieval-Augmented Generation (RAG) application that enables you to upload and query multiple documents in natural language.
Supports multi-file upload, optional file-specific Q&A, document history tracking, and clearing uploaded data â€” all with a simple, user-friendly interface.

Built with FastAPI, Streamlit, LangChain, HuggingFace, and ChromaDB.

--------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸš€ Features
ğŸ“‚ Multi-file upload â€” upload PDFs, TXT, DOCX one by one and store them in the knowledge base.
ğŸ” Ask multiple questions â€” query across all uploaded documents or select a specific file for targeted answers.
ğŸ“œ Document history â€” fetch and display the list of previously uploaded documents.
ğŸ—‘ Clear history â€” remove all stored documents and embeddings from the database in one click.
âš¡ Real-time Q&A â€” get concise, context-aware answers using LLMs with RAG.

--------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ—ï¸ Tech Stack
Frontend: Streamlit
Backend: FastAPI
LLM Framework: LangChain
Embeddings: sentence-transformers/all-MiniLM-L6-v2 (HuggingFace)
Vector DB: ChromaDB
LLM API: OpenAI-compatible endpoint (configurable)

--------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ“‚ Project Structure

genai-doc-qa/
â”‚â”€â”€ app/                  # Backend (FastAPI)
â”‚â”€â”€ frontend/             # Streamlit app
â”‚â”€â”€ test_files/           # Diagnostic & smoke test scripts
â”‚â”€â”€ docs/                 # Example documents
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ Dockerfile            # Deployment setup
â”‚â”€â”€ README.md             # Project documentation

--------------------------------------------------------------------------------------------------------------------------------------------------------------

âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the repo
git clone https://github.com/yourusername/genai-doc-qa.git
cd genai-doc-qa


2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
3ï¸âƒ£ Set environment variables
Create a .env file:

env
A4F_API_KEY=your_api_key
A4F_BASE_URL=https://api.a4f.ai/v1
LLM_MODEL_NAME=gpt-3.5-turbo

4ï¸âƒ£ Run backend (FastAPI)
uvicorn app.main:app --reload

5ï¸âƒ£ Run frontend (Streamlit)
streamlit run frontend/app.py

--------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ§ª Running Tests

Example:
python test_files/app.py           # Ingest documents
python test_files/inspect_db.py    # Inspect vector DB contents
python test_files/model.py         # Test LLM connectivity
python test_files/test_query.py    # Run sample Q&A query

--------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ“¦ Deployment

With Docker:
docker build -t genai-doc-qa .
docker run -p 8000:8000 genai-doc-qa
Or deploy to Streamlit Cloud, Hugging Face Spaces, or AWS.

ğŸ—‚ Example Usage Flow

1. Upload Documents â†’ Add files one by one in PDF, TXT, or DOCX format.

2. View History â†’ Check the list of all uploaded documents in the interface.

3. Ask Questions â†’ Query across all documents, or select a specific file for targeted answers.

4. Clear History â†’ Remove all stored files and embeddings with one click.

ğŸ“Œ Roadmap
 Add support for batch file upload.

 Implement streaming responses for faster UX.

 Add hybrid search (BM25 + embeddings) for better retrieval.

 Integrate authentication for multi-user support.

ğŸ‘¨â€ğŸ’» Author
Your Name â€” Pradunya Rajendra SArode