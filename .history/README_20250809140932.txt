📄 GenAI Multi-Document Q&A System
An advanced Retrieval-Augmented Generation (RAG) application that enables you to upload and query multiple documents in natural language.
Supports multi-file upload, optional file-specific Q&A, document history tracking, and clearing uploaded data — all with a simple, user-friendly interface.

Built with FastAPI, Streamlit, LangChain, HuggingFace, and ChromaDB.

--------------------------------------------------------------------------------------------------------------------------------------------------------------

🚀 Features
📂 Multi-file upload — upload PDFs, TXT, DOCX one by one and store them in the knowledge base.
🔍 Ask multiple questions — query across all uploaded documents or select a specific file for targeted answers.
📜 Document history — fetch and display the list of previously uploaded documents.
🗑 Clear history — remove all stored documents and embeddings from the database in one click.
⚡ Real-time Q&A — get concise, context-aware answers using LLMs with RAG.

--------------------------------------------------------------------------------------------------------------------------------------------------------------

🏗️ Tech Stack
Frontend: Streamlit
Backend: FastAPI
LLM Framework: LangChain
Embeddings: sentence-transformers/all-MiniLM-L6-v2 (HuggingFace)
Vector DB: ChromaDB
LLM API: OpenAI-compatible endpoint (configurable)

--------------------------------------------------------------------------------------------------------------------------------------------------------------

📂 Project Structure

genai-doc-qa/
│── app/                  # Backend (FastAPI)
│── frontend/             # Streamlit app
│── test_files/           # Diagnostic & smoke test scripts
│── docs/                 # Example documents
│── requirements.txt      # Python dependencies
│── Dockerfile            # Deployment setup
│── README.md             # Project documentation

--------------------------------------------------------------------------------------------------------------------------------------------------------------

⚙️ Installation & Setup

1️⃣ Clone the repo
git clone https://github.com/yourusername/genai-doc-qa.git
cd genai-doc-qa


2️⃣ Install dependencies
pip install -r requirements.txt
3️⃣ Set environment variables
Create a .env file:

env
A4F_API_KEY=your_api_key
A4F_BASE_URL=https://api.a4f.ai/v1
LLM_MODEL_NAME=gpt-3.5-turbo

4️⃣ Run backend (FastAPI)
uvicorn app.main:app --reload

5️⃣ Run frontend (Streamlit)
streamlit run frontend/app.py

--------------------------------------------------------------------------------------------------------------------------------------------------------------

🧪 Running Tests

Example:
python test_files/app.py           # Ingest documents
python test_files/inspect_db.py    # Inspect vector DB contents
python test_files/model.py         # Test LLM connectivity
python test_files/test_query.py    # Run sample Q&A query

--------------------------------------------------------------------------------------------------------------------------------------------------------------

📦 Deployment

With Docker:
docker build -t genai-doc-qa .
docker run -p 8000:8000 genai-doc-qa
Or deploy to Streamlit Cloud, Hugging Face Spaces, or AWS.

🗂 Example Usage Flow

1. Upload Documents → Add files one by one in PDF, TXT, or DOCX format.

2. View History → Check the list of all uploaded documents in the interface.

3. Ask Questions → Query across all documents, or select a specific file for targeted answers.

4. Clear History → Remove all stored files and embeddings with one click.

📌 Roadmap
 Add support for batch file upload.

 Implement streaming responses for faster UX.

 Add hybrid search (BM25 + embeddings) for better retrieval.

 Integrate authentication for multi-user support.

👨‍💻 Author
Your Name — Pradunya Rajendra SArode